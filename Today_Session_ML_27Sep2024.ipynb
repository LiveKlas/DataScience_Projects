{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kXLQHLscm5rY",
        "f_voshO8oj1I",
        "lKkZsyFJpdjT",
        "qqyfE17qFOVs"
      ],
      "authorship_tag": "ABX9TyNfeWCZdKvDqT0mgXDBBlvR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LiveKlas/DataScience_Projects/blob/main/Today_Session_ML_27Sep2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Learning Algorithms**"
      ],
      "metadata": {
        "id": "b5jwXqf1_pai"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ML algorthims are computational models that allow computers to understand patterns and forecast or make judgements based on data without explicit programming.\n",
        "\n",
        "These algorithms form the foundation of modern AI and are used in various applications, including image and speech recognition, NLP, Recommendation Systems, fraud detection, autonomous cars, etc.,\n",
        "\n",
        "SVM, Decision Making, logistics regression, Naive Bayes Classifier, random forest, k-mean clustering, reinforcement learning, xgboost, adaboost, etc.,"
      ],
      "metadata": {
        "id": "o1MzkIjH_vxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Types of ML Algorithms**\n",
        "\n",
        "Four types of ML algorithms\n",
        "\n"
      ],
      "metadata": {
        "id": "8HiEWrmbCJYa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "X7WaPopnEIvr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Supervised Learning**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "AIMxfBXcCUBi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised learning involves training a model on label data, where the desired output is known. The model learns to map inputs to outputs based on the provided examples."
      ],
      "metadata": {
        "id": "ae89kFviK-uA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A. Classification**\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mzC_7b2zCZfK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Logistic Regression**\n",
        "* **Support Vector Machines (SVM)**\n",
        "* **k-Nearest Neighbors (k-NN)**\n",
        "* **Naive Bayes**\n",
        "* **Decision Trees**\n",
        "* **Random Forest**\n",
        "* **Gradient Boosting(e.g., XGBoost,CatBoost, LightGBM)**\n",
        "* **Neural Networks(e.g., Multilayer Perception)**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "lDCMzmi1CgXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1. Logistic Regression**"
      ],
      "metadata": {
        "id": "yqJZCNBfk-Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Logistic regression models, probability of a binary outcome using logistic function. It outputs probabilities and classifies instances by setting a threshold(usually 0.5)\n",
        "\n",
        "* **Key Points:**\n",
        "    * Simple and easy to implement.\n",
        "    * Assumes linear relationship between the input features and the log-odds of the outcome.\n",
        "    * Works well for binary classification problems.\n",
        "\n",
        "* **Applications:** Email spam detection, disease dignosis, credit scoring.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yFgKgowllQxu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **2. Support Vector Machines (SVM)**"
      ],
      "metadata": {
        "id": "kXLQHLscm5rY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** SVMs find the hyperplane that best separates different classes by maximizing the margin between them.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Effective in high-dimensional spaces.\n",
        "  * Works well for both linear and non-linear classificaion using kernel trick.\n",
        "  * Sensitive to the choice of kernel and regularization parameter.\n",
        "\n",
        "* **Applications:** Image classification, text categorization, bioinformatics.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "zlNCPHsqnDE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **3. k-Nearest Neighbors (k-NN)**"
      ],
      "metadata": {
        "id": "f_voshO8oj1I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** k-NN classifies instances based on majority class among the k-nearest neighbors in the feature space.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Simple and intuitive.\n",
        "  * No explicit training phase, making it a lazy learner.\n",
        "  * Sensitive to the choice of k and the distance metric.\n",
        "\n",
        "* **Applications:** Recommender systems, pattern recognition, anomaly detection.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "6SDgxD2Pouj6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **4. Naive Bayes**"
      ],
      "metadata": {
        "id": "lKkZsyFJpdjT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Naive Bayes uses Bayes' theorem with the assumption of feature independence to classify instances.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Fast and efficient.\n",
        "  * Performs well with high-dimensional data.\n",
        "  * Assumtion of feature independence might not hold in all cases.\n",
        "\n",
        "* **Applications:** Text classification, semantic analysis, spam filtering.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HL9oCPMwpe2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **5. Decision Trees**"
      ],
      "metadata": {
        "id": "6V9UJj5Gqf70"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Decision trees split data into subsets based on the value of input features, creating a tree like model of decisions.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Easy to interpret and visualize.\n",
        "  * Can handle both numerical and categorical data.\n",
        "  * Prone to overfititng without proper pruning.\n",
        "\n",
        "* **Applications:** Risk Assessment, fraud detection,customer segmentation.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "7HxfEA5sqgmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **6. Random Forest**"
      ],
      "metadata": {
        "id": "atykIXWKrlYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Random forest is an ensemble of decision trees that improves accuracy and controls overfitting by averaging multiple trees trained on different subsets of data.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Reduces overfitting compared to individual decision trees.\n",
        "  * Handles large datasets with higher dimensionality.\n",
        "  * Requires more computational resources.\n",
        "\n",
        "* **Applications:** Financial forecasting, image classification, healthcare diagnostics.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "GfpkrKkarm3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **7. Gradient Boosting(e.g., XGBoost,CatBoost, LightGBM)**"
      ],
      "metadata": {
        "id": "GCYPrYRPvAcy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Gradient boosting builds models sequentially to correct errors made by previous models, optimizing for accuracy.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Highly accurate and efficient.\n",
        "  * Can handle different types of data.\n",
        "  * Prone to overfitting if not properly tuned.\n",
        "\n",
        "* **Applications:** Web search ranking, customer churn predition, insurance risk prediction.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "hRvkN4AHvA1P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **8. Neural Networks(e.g., Multilayer Perception)**"
      ],
      "metadata": {
        "id": "6TEjalGKxkcF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Neural networks use layers of interconnected nodes to modal complex patterns in data.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Capable of learning non-linear relationships.\n",
        "  * Requires large amounts of data and computational power.\n",
        "  * Can be prone to overfitting.\n",
        "\n",
        "* **Applications:** Image recognition, speech recognition, Natural Language Processing (NLP).\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cvtqqbo5d_I3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **B. Regression**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "U2CN3jbNELs6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Linear Regression**\n",
        "* **Ridge Regression**\n",
        "* **Lasso Regression**\n",
        "* **Support Vector Regression(SVR)**\n",
        "* **Decision Trees Regression**\n",
        "* **Random Forest Regression**\n",
        "* **Gradient Boosting Regression**\n",
        "* **Neural Networks Regression**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "H-YJVdM7EZbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **1. Linear Regression**"
      ],
      "metadata": {
        "id": "D2Q-IWngfiRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Linear regression models the relationship between dependent and independent variables using a linear approach.\n",
        "\n",
        "* **Key Points:**\n",
        "    * Simple and easy to implement.\n",
        "    * Assumes linear relationship between the variables.\n",
        "    * Senstive to outliers.\n",
        "\n",
        "* **Applications:** House price prediction, Sales Forecasting, Risk Management.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B9-ALPOhfqIU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **2. Ridge Regression**"
      ],
      "metadata": {
        "id": "XT2aSWlogoJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Rudge regression adds L2 regularization to linear regression to handle multicollinearity and prevent overfitting.\n",
        "\n",
        "* **Key Points:**\n",
        "    * Shrinks coefficients to reduce overfitting.\n",
        "    * Handles multicollinearity well.\n",
        "    * Requires tuning of the regularization parameter.\n",
        "\n",
        "* **Applications:** Economic forecasting, portfolio optimization, marketing analysis.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EmjMa5oXgsoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **3. Lasso Regression**"
      ],
      "metadata": {
        "id": "Bvb5bNRXheod"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Lasso regression adds L1 regularization to linear regression to perform feature selection by shrinking some coefficients to zero.\n",
        "\n",
        "* **Key Points:**\n",
        "    * Performs feature selection.\n",
        "    * Can produce sparse models.\n",
        "    * Requires tuning of the regularization parameter.\n",
        "\n",
        "* **Applications:** Gene selection, model selection, finance.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BIU1vuANhmkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **4.Support Vector Regression(SVR)**"
      ],
      "metadata": {
        "id": "6uWid6YFiFSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** SVR uses Support Vector Machines (SVM) for regression tasks by finding a function that deviates from the actual target values by a value no greater than a specified margin.\n",
        "\n",
        "* **Key Points:**\n",
        "    * Effective in high-dimensional spaces.\n",
        "    * Robust to outliers.\n",
        "    * Senstive to the choice of kernel and regularization parameter.\n",
        "\n",
        "* **Applications:** Time series prediction, stock price forecasting, real estate valuation.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bneMGQzKiRgm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Support Vector Regression (SVR)**\n",
        "\n",
        "* **Description:** SVR is an extension of Support Vector Machines (SVM) for regression tasks. It aims to find a hyperplane that best fits the data points while minimizing errors within a defined margin (epsilon).\n",
        "\n",
        "* **Key Points:**\n",
        "  * Effective in handling non-linear relationships using kernel functions (similar to SVM).\n",
        "  * Robust to outliers due to the epsilon-insensitive loss function.\n",
        "  * Requires tuning of hyperparameters like C (regularization parameter) and epsilon (margin).\n",
        "\n",
        "**Applications:**\n",
        "* Time series forecasting\n",
        "* Financial modeling\n",
        "* Function approximation"
      ],
      "metadata": {
        "id": "SsDvOeQOjr5M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **5.Decision Trees Regression**"
      ],
      "metadata": {
        "id": "jbAE8bHFk0hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Decision trees regression splits data into subsets to predict contiu=nuous values.\n",
        "\n",
        "* **Key Points:**\n",
        "    * Easy to interpret and visualize.\n",
        "    * Can handle both numerical and categorical data.\n",
        "    * Prone to overfitting without proper pruning.\n",
        "\n",
        "* **Applications:** Business forecasting, medical diagnosis, Engineering.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "csrcwGBplJcf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **6. Random Forest Regression**"
      ],
      "metadata": {
        "id": "jbWqyxiclFSV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Random forest regression is an ensemble of decision trees for regression tasks, averaging the predictions to improve accuracy and control overfitting.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Reduces overfitting compared to individual decision trees.\n",
        "  * Handles large datasets with higher dimensionality.\n",
        "  * Requires more computational resources.\n",
        "\n",
        "* **Applications:** Environmental modeling, energy demand forecasting, market analysis.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "dIP6H8S9nqTc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **7. Gradient Boosting Regression**"
      ],
      "metadata": {
        "id": "EPe-OVQjpKI5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Description:** Gradient boosting regression sequentially builds models to improve predictions by correcting errors made by previous models.\n",
        "\n",
        "* **Key Points:**\n",
        "  * Highly accurate and efficient.\n",
        "  * Can handle different types of data.\n",
        "  * Prone to overfitting if not properly tuned.\n",
        "\n",
        "* **Applications:** Housing price prediction, customer lifetime value prediction.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MJ6wi2VjpdaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ciEp9kCopSzl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2. Unsupervised Learning**\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qqyfE17qFOVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A. Clustering**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "b7H4AfeWFXYR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **k-Means**\n",
        "* **Hierarchical Clustering**\n",
        "* **DBSCAN (Density-Based Spatial Clusterting of Applications with Noise)**\n",
        "* **Guassian Mixture Models(GMM)**\n",
        "\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "-PNaTQ8bFaOa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **B. Dimensionality Reduction**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "_IPe2WhoGL0r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Principal Component Analysis (PCA)**\n",
        "* **t-Distributed Stochastic Neighbor Embedding (t-SNE)**\n",
        "* **Linear Discriminant Analysis (LDA)**\n",
        "* **Independent Component Analysis (ICA)**\n",
        "* **Uniform Manifold Approximation and projection (UMAP)**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4pLgELD4GV7-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **C. Association**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "K4ilF8zxGUST"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Apriori Algorithm**\n",
        "* **Eclat Algorithm**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "U_SOJxWrHhr8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **3. Reinforcement Learning**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "3eN6z8QxHuHS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **A. Model-Free Methods**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UNQNhfizIDeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Q-Learning**\n",
        "* **Deep Q-Network (DQN)**\n",
        "* **SARSA (State-Action-Reward-State-Action)**\n",
        "* **Policy Gradient Methods(e.g., REINFORCE)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "-lPIb0QpILYN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **B. Model-Based Methods**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "pJ7Y6VjiIwz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Deep Deterministic Policy Gradient (DDPG)**\n",
        "* **Proximal Policy Optimization (PPO)**\n",
        "* **Trust Region Policy Optimization (TRPO)**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "f7ybAAUWI1AV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **C. Value-Based Methods**\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "OI2GmVUkJW-x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Monte Carlo Methods**\n",
        "* **Temporal Difference (TD) Learning**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wlh32eTdJeT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4. Ensemble Learning**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "cyRi9DOHJySF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Bagging (e.g., Random Forest)**\n",
        "* **Boosting (e.g.,AdaBoost, Gradient Boosting)**\n",
        "* **Stacking**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MXD5xYG7J7Iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CYmqNCkBKmBq"
      }
    }
  ]
}